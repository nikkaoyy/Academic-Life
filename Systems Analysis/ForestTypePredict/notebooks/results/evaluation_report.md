# Forest Cover Type Prediction: Model Comparison Report

**Date**: 2025-11-27 01:12:31

## Executive Summary

This report compares **XGBoost** and **LightGBM** performance on the Forest Cover Type dataset using 5-fold stratified cross-validation.

## Dataset

- **Samples**: 15,120
- **Features**: 55
- **Classes**: 7

## Performance Metrics

### Overall Accuracy

| Model | Mean | Std Dev |
|-------|------|---------|
| XGBoost | 0.8866 | 0.0054 |
| LightGBM | 0.8937 | 0.0044 |

### F1-Score (Macro)

| Model | Mean | Std Dev |
|-------|------|---------|
| XGBoost | 0.8850 | 0.0056 |
| LightGBM | 0.8923 | 0.0045 |

### Computational Performance

| Model | Train Time (s) | Memory (MB) |
|-------|---------------|-------------|
| XGBoost | 5.16 ± 0.67 | 34.0 ± 52.9 |
| LightGBM | 4.98 ± 0.60 | -4.8 ± 36.3 |

## Recommendation

**Winner**: LightGBM

**Rationale**: LightGBM achieves higher accuracy.

## Next Steps

1. Retrain winning model on full dataset
2. Perform hyperparameter optimization with Optuna
3. Deploy to production API
4. Monitor performance in chaos zones

---

*Generated by Forest Cover Type Prediction System*
